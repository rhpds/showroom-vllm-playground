= Module 4: MCP integration for agentic workflows
:source-highlighter: rouge
:toc: macro
:toclevels: 1

In Module 3, ACME's AI learned to generate function calls for backend system integration. But function call generation alone doesn't execute actions - someone or something must run the tools and return results to the AI.

Model Context Protocol (MCP) provides the missing piece: a standardized way to connect AI models to external tools with safe execution and result handling. This module demonstrates how ACME implements production-ready agentic workflows with human-in-the-loop approval.

**Critical understanding**: MCP is an open protocol that enables AI applications to securely connect to data sources and tools. It provides the infrastructure for executing tool calls generated by the AI, with enterprise controls like approval workflows and audit logging.

**Presenter note**: This module is optional for 60-minute deep dives. It demonstrates the complete tool execution cycle that makes tool calling production-ready.

== Part 1 — Understanding MCP for enterprise AI

=== Know

_Module 3 showed tool call generation, but ACME needs the complete picture: How do those function calls actually execute? Who controls execution? How do results return to the conversation? How do we maintain security and compliance?_

**Business challenge**: Safe, controlled tool execution at scale

* Tool call generation (Module 3) only creates JSON - it doesn't execute anything
* Manual tool execution doesn't scale for thousands of daily customer interactions
* Enterprises need approval workflows before AI executes sensitive actions
* Audit logging and compliance require tracking what AI did and why

**Current state limitations without MCP**:

* **No execution framework**: Function calls are generated but never executed
* **No human oversight**: Can't implement approval gates for sensitive operations
* **No result handling**: Can't return execution results to AI conversation flow
* **Compliance gaps**: No audit trail of AI-initiated actions

**Desired state with MCP**:

* Standardized protocol for connecting AI to tools across any environment
* Human-in-the-loop approval for sensitive operations (callbacks, refunds, account changes)
* Automatic execution for safe operations (order status lookup, product search)
* Full audit trail of tool execution for compliance and debugging

**Business value proposition**:

MCP transforms tool calling from a demo feature into production-ready agentic AI. ACME can safely automate customer support workflows with appropriate human oversight and full compliance tracking.

**Quantified business impact**:

* **Production-ready automation**: Move from function call demos to actual execution
* **Controlled AI autonomy**: Approve sensitive actions while auto-executing safe lookups
* **Compliance and audit**: Complete execution logs for regulatory requirements
* **Ecosystem integration**: Standard protocol works with any backend system or tool

**Stakeholder impact**:

* **Compliance Teams**: Audit trail of all AI-initiated actions with approval records
* **Operations Leaders**: Control which actions require human approval vs automatic execution
* **Customer Support**: Fast execution for lookups, safe controls for account modifications
* **IT Integration**: Standard MCP protocol simplifies tool development and maintenance

=== Show

**Presenter guidance**: Demonstrate the complete tool execution cycle with MCP. Show both automatic execution (safe lookups) and human-in-the-loop approval (sensitive actions).

**What to demonstrate**:

. **Access vLLM Playground** (15 seconds):
+
Open browser to: http://{targethost}:7860
+
**Business context**: "Continuing from Module 3 where we defined tools. Now we'll connect those tools to actual execution via MCP."

. **Navigate to MCP panel** (30 seconds):
+
**Click the MCP icon in the toolbar**
+
**Business context**: "The MCP panel shows available MCP servers - each server provides tools that the AI can use. vLLM Playground acts as the MCP client, connecting to these servers."

. **Show available MCP servers** (2-3 minutes):
+
**Point out pre-configured servers**:
+
* **filesystem** server: File operations (read, write, list directories)
* **fetch** server: Web content retrieval
* **puppeteer** server: Web browser automation
* **memory** server: Long-term memory storage for the AI
+
**Business talking point**: "These are pre-built MCP servers from the community. ACME can use these directly or build custom servers for their CRM, order management, and inventory systems."

. **Enable an MCP server** (1 minute):
+
**Select and enable a server** (e.g., filesystem for demo simplicity)
+
**Business talking point**: "Enabling an MCP server makes its tools available to the AI. When the AI generates a tool call, vLLM Playground routes it to the appropriate MCP server for execution."

. **Test MCP tool execution** (3-4 minutes):
+
**Navigate to Chat interface**
+
**Send request that triggers MCP tool**:
+
----
Can you list the files in the /tmp directory?
----
+
**What they'll see**:
+
* AI generates a function call to the filesystem MCP server
* vLLM Playground sends the request to the MCP server
* MCP server executes the file listing
* Results return to the AI conversation
* AI formats the results for the customer
+
**Business value callout**: "This is the complete cycle: AI generates tool call → MCP server executes → Results return to conversation → AI presents findings to customer. ACME would connect this same pattern to their order management API."

. **Demonstrate human-in-the-loop approval** (3-4 minutes):
+
**Configure approval setting** (if available in UI):
+
* Show how to mark certain tools as requiring approval
* Explain approval workflow: Tool call generated → Human reviews → Approve/Reject → Execute
+
**Business talking point**: "For sensitive operations like processing refunds or changing customer accounts, ACME would configure approval requirements. The AI generates the call, a supervisor reviews and approves, then execution proceeds. This maintains human oversight for critical actions."

. **Show execution audit trail** (2 minutes):
+
**Point to MCP execution logs** (if available):
+
* Tool called, parameters, timestamp
* Execution result or error
* Approval status (if applicable)
+
**Business talking point**: "Every MCP tool execution is logged. For compliance, ACME can prove exactly what the AI did, when, with what parameters, and whether it was approved. This audit trail is critical for regulated industries."

**Business value summary**:

"MCP provides the missing infrastructure for production AI agents. ACME can now execute tool calls safely with human approval for sensitive operations, automatic execution for safe lookups, and complete audit trails for compliance. This is how demonstrations become production deployments."

**Troubleshooting scenarios to be ready for**:

**Q: "How do we build custom MCP servers for our internal systems?"**
→ A: MCP is an open protocol with SDKs for Python, TypeScript, and other languages. Your team builds an MCP server that exposes your APIs as tools, then vLLM Playground connects to it.

**Q: "Can we control which users can approve which actions?"**
→ A: Yes. ACME would implement role-based access control in their approval workflow. Supervisors approve refunds, technicians approve config changes, etc.

**Q: "What about rate limiting and quotas?"**
→ A: MCP servers can implement their own rate limiting, quotas, and throttling. Your server controls execution policy.

**Q: "How does this integrate with our existing approval systems?"**
→ A: MCP tool calls can trigger your existing approval workflows (ServiceNow, Jira, custom systems). The MCP server waits for approval before executing.

== Part 2 — Advanced MCP patterns (Optional - if time permits)

=== Know

_Production AI deployments require sophisticated patterns: Long-running operations, error handling, tool chaining, and multi-server coordination._

**Advanced MCP capabilities**:

* **Tool chaining**: AI calls multiple tools in sequence based on results
* **Error handling**: MCP servers return structured errors that AI can explain
* **Async operations**: Long-running tools with progress updates
* **Multi-server workflows**: Combining tools from different MCP servers

=== Show

**Presenter guidance** (only if extra time): Briefly mention advanced patterns without deep demonstration.

**Key points to cover**:

* **Tool chaining**: "The AI can call get_order_status, then based on the result, call schedule_callback if there's an issue."
* **Error handling**: "If an MCP tool fails (API timeout, invalid data), the AI receives a structured error and can explain it to the customer or retry."
* **Production patterns**: "ACME would deploy multiple MCP servers - one for CRM, one for orders, one for inventory - and the AI coordinates across all of them."

**Business value summary for advanced patterns**:

"Advanced MCP patterns enable ACME to build sophisticated multi-system workflows where the AI orchestrates actions across CRM, order management, inventory, and shipping systems - all through natural conversation."

== Demonstration outcomes

By seeing this demonstration, audiences should understand:

* ✓ How MCP completes the tool calling picture with actual execution
* ✓ The business value of human-in-the-loop approval for sensitive operations
* ✓ How audit trails enable compliance and debugging
* ✓ The pattern for building custom MCP servers for internal systems
* ✓ Real-world application to production agentic workflows

== Module summary

**What ACME accomplished**:

* Connected vLLM Playground to MCP servers for tool execution
* Demonstrated complete tool execution cycle (call → execute → results → AI response)
* (Optional) Showed human-in-the-loop approval workflow
* Explored MCP ecosystem of pre-built servers

**Key takeaways for technical audiences**:

* MCP is an open protocol for connecting AI to tools with safe execution
* vLLM Playground acts as MCP client, routing tool calls to appropriate servers
* Human-in-the-loop approval enables safe AI autonomy
* Audit logging provides compliance and debugging capabilities

**Business value delivered**:

* **Production-ready agents**: Move from demos to actual automated workflows
* **Controlled autonomy**: Human approval for sensitive ops, auto-execution for safe lookups
* **Compliance**: Complete audit trail of AI actions
* **Standard protocol**: MCP works across any backend system or tool ecosystem

**Next module preview**:

Module 5 explores *Performance Testing and Benchmarking* - validating that ACME's vLLM infrastructure can handle production workloads. You'll see how to measure throughput, latency, and resource utilization using GuideLLM benchmarking tools. This provides the quantified data needed for capacity planning and SLA commitments.
